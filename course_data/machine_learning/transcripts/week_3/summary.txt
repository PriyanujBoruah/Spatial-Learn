Week 3 focuses on Linear Regression, a fundamental supervised learning algorithm for predicting a continuous target variable. The week begins by establishing a baseline model using DummyRegressor to provide a benchmark for performance. The core of the week is an in-depth exploration of the SGDRegressor, which implements Stochastic Gradient Descent and is particularly well-suited for large datasets.

A significant portion of the week is dedicated to understanding and tuning the various hyperparameters of the SGDRegressor to gain greater control over the optimization process. This includes setting the loss function (e.g., 'squared_error' for ordinary least squares or 'huber' for robust regression), penalty for regularization (L1, L2, or Elastic Net), learning_rate schedule (constant, optimal, inverse scaling, or adaptive), and various stopping criteria to prevent overfitting and manage training time.

The week also covers practical aspects of model development, including model inspection (accessing the learned weights and intercept), model inference (making predictions on new data), and model evaluation. A variety of evaluation metrics from sklearn.metrics are introduced, such as mean_absolute_error, mean_squared_error, and r2_score.

Finally, to ensure a robust and reliable assessment of model performance, the concept of Cross-Validation is introduced. Different cross-validation strategies like KFold, LeaveOneOut, and ShuffleSplit are explained, providing methods to estimate the variability of the model's generalization performance. The week concludes by showing how to use learning curves to diagnose underfitting or overfitting by studying the effect of the number of training samples on training and test errors.