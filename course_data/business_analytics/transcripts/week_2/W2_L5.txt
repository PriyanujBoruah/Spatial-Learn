So, welcome back and here we are going to take a look at the second data set and guess the distribution. So, similar to the previous data set we use the same steps like doing the descriptive statistics followed by visual inspection and then moving on to statistical test. So, without any further delay let us look at the data set. So, again as usual we have a single call. So, this time we have around 49 counts which means that we have 48 observations and one header. So, I do not think we can do derive a lot of insights from this excel file. So, therefore let us load it on to the Google collaborator and then start with the descriptive statistics, all right as usual the regular formalities which include importing Numpy and pandas, reading the excel file, printing the excel file. So, we have 48 observations and then the first step is histogram. Malo over to you. So, this histogram very looks very appeasing to the eye why is that because it has one huge building one skyscraper then a couple of skyscrapers on the side and something to the extreme ripe. So, the first order of business is this is somewhat Gaussian in nature that we can by default fix in our head. So, there is one peak a couple of peaks around it and one side the important thing to note in this histogram is that side bit that is sitting between 90 to 100. So, that is actually inclining towards something. It is telling us that there are more or there are significant number of observations that are towards one side which means the distribution is having a tail which is on the right side. So, that is one in fact that is something interesting from this histogram apart from telling that it could be a Gaussian it is also telling that it could be a Gaussian at the right tail. So, whenever we see histogram it will be really placing twice if you find it in this way right that most of the students want the histogram to be in this kind of format, exactly. But unfortunately normal is only theoretical but we do a lot of tests and assuming stuff to be normal because that is something that all statisticians love. But in real life when the data is extremely large then you can start assuming it to be normal but it need not be the case. But like you said Swami a distribution like this where you have a peak and then buildings around it and then something on the side it is always appeasing to the end. So, next let us have a look at the basic descriptive stats the mean seems to be 56.95 and the standard deviation is relatively low. So, we have around 14.87 as standard deviation. So, the minimum value is 27 and the maximum value is 101 and the median is 56. One second Swami, there is something interesting in this particular summary statistics which is if you see between 57 and 48 the minimum and the 25th quantile it is around 20 all right between 25 and 50 it is around 10 and 50 to 75 another 10 whereas from 75 to the maximum it is more than 30 which means at the tail on the unit, fantastic. And the other interesting thing is mean and median are almost same which means example you know that is huge symmetry with a slight tail. So, that is what the summary statistics if you look at it along with the histogram you can actually derive a lot of insights from them whatever your visualization is actually being concreted by these statistics. So, let us also look at the important parameters like skewness and kurtosis and skewness seems to be 0.37 and kurtosis is 0.6. So, whenever you have a positive skew it means the distribution is right tail values are more than the mean, yes. So, everything is now falling into place or whatever we observe whatever we thought or descriptive statistics is actually reinforcing our visualization that is also now reinforced by statistical concepts of skewness and kurtosis, beautiful. So, the next step is again median which we already got it from the descriptive stats again it is 56 may not be of much help now . So, again we'll download the required packages. Next is the Q-Q plot. So, let us see how the Q-Q plot looks like. And as usual we have the df of observation which is the data set and we do not have anything to compare it with because the by default it is going to compare with the normal distribution. It is going to compare with the standard normal distribution . In this case what the code actually does is; it converts the data that is fed to it to a standard normal. To scale it basically by doing x minus mu by sigma it will scale it and then it will compare it with the standard normal and see how the quantiles are fitting. Yes, that is what the right word to use is normalizing. So, it will normalize the data. So, that is the terminology that I should have used, so it will normalize the data and then compare it with the standard normal. So, if you see this is a perfect fit you will not get a more better fit in real life scenarios. So, this is actually a perfect fit and the Q-Q plot says that it is a normal distribution very true. So, let us also look at the story behind the probability plot or P-P plot and exactly the same thing. So, P-P plot is comparing it with the CDF. Q-Q plot is comparing the quantities and both are telling the same thing we can close our guess now. So, let us call it normal distribution for now we can call it the further steps in fact that we are going to do after getting all of these we can actually 95% say it is normal and no one will question you but just for the sake of that 5% you will say no I want that statistic we will go into and show how to do a Chi square statistics. Now test for this particular data set, got it. So, now let us split this data into 6 equal intervals for example let us say we have a normal curve. So, let us divide it into 6 equal intervals. So, as you all know the area under the curve is one. So, if you divide it by six the area under each bucket will be around 0.166 or 0.167. So, this is what I have chosen to divide the data into 6 intervals. So, therefore I am using n as 1 by 6. And you can use any number you can divide it by 7, 8, 9 whatever and accordingly a future we will change we will tell you how to change the podium for now we are doing 6. So, another usual formality import scipy dot stats. So, now what I am doing is I am actually using this term called scipy dot stats dot now dot ppf remember we calculated the Poisson probability using a similar function. So, similarly I am using this for the normal distribution where I have the number of classes here which is 6 and then I have the parameters of normal distribution which are nothing but mean and standard deviation right using two parameters yes which is mean and standard deviation. And then let us print this variable called probability intervals. So, we had divided this into 6 equal intervals for which I am calculating the probability intervals. So, right now we have around 5 values. So, which means that we can split the data say below 42 to 42 in one bucket 42 to 50.55 in the second bucket 50.55 to 56.95 in the third bucket and then 56.95 to 63.36 in the next bucket and 63.36 to 71.34 in the last bucket or the sixth bucket right and if you calculate it manually. So, you will see the observed frequency which is 9 7 9 7 9 7. So, we can say that between I mean less than 42.51 to 42.57 we had 9 observations. So, as an exercise maybe students can open the excel file and you know do a filter we do not have to do it Swami let the students do it to just check whether our numbers are. So, they can open the excel file put a filter go to the numerical filters okay let us do it for one. So, that people understand it better all right fine fair enough if you can add a filter okay. So, now let me also arrange it in ascending order. So, we saw this interval 42.57. So, if you look at this. So, there will be nine observations exactly and let us take a look at the next seven observations. So, you have till you have from 45 to 50. So, that is the second bucket 42 to 50 is the second bucket. So, likewise we have created six buckets and we have the observed frequency as 9 7 9 7 9 7 and so on. So, since we are splitting this into six buckets. So, we told you that I am taking n as one by six and we had 48 observations. So, which means the expected frequency under each bucket is nothing but 48 divided by 6 which is 8. So, that is why I have the expected frequency as eight under each bucket. So, we have two lists one is expected frequency other one is the observed frequency. So, as usual let us get into the chi square test between the observed frequency and the expected frequency. So, again we have a p-value of 0.9948 it is a very strong p-value which is very greater than 0.05, 0.1 or 0.15 which ever alpha value you want to use. So, you will at this point according to p value you can say that you do not reject the null hypothesis and what is the null hypothesis take a pause. So, the null hypothesis is going to be that the observed sample is following a normal distribution and the alternative is that it is not following a normal distribution. So, since the p value is 0.99 which is greater than your alpha you are going to conclude saying that yes this distribution follows a normal okay. So, hold on the suspense we have another question for you. So, let us also confirm this using the calculated value and tabulated value of the chi-square statistic. As you all know the calculated value of chi-square statistic is 1.0 what should be the tabulated value of chi square statistic should it be greater or lesser. So, that is up to you. So, we already have a calculated chi square statistic of 1.0. So, now let us check it with the tabulated value of chi square statistic for which I am using this library called scipy dot stats and the syntax is chi square dot tpf and we have two parameters or two arguments one is 0.95 and other is 3 where 0.95 is the confidence level say 95 percent and then 3 is nothing but the degrees of freedom and Malo the degrees of freedom. So, the degrees of freedom is basically going to be k minus p minus 1. So, k is the number of buckets. So, we used 6 intervals. So, it is 6 minus 1 which is 5, p is the number of parameters we compute from the sample. So, in this case for normal we need the mean and the variance. So, we have computed two parameters. So, 6 minus 2 minus 1 which is 3. So, chi squared of 0.95, 3 and the value for that is 7.8 which means we since 7.8 is greater than 1 we do not reject the null hypothesis and hence this is coming from a normal population distribution. Malo, would you also like to talk about the business cases of normal distribution, sure.When we talk about normal most of our life events can be assumed to be normal one such thing all of us would have taken a test. So, our test scores over the years could be a normal distribution or test course of an entire class will be normally distributed. So, those are all real life examples of the normal distribution anything else from your and Swami can you think of in fact if you look at this data which I got. So, this comes from from automotive sales. So, there were around 48 salesmen who have sold tractors on a particular month. So, ideally you will see a couple of people who are performing extremely well and there will be some salesmen who may not be performing well and in between you will have the majority of people. So, that is again a beautiful example for normal distribution. All right with this we conclude this tutorial on normal distribution.