Hello, everyone. Welcome to this lecture on the implementation of the chi-square test of independence in python. I am S. Srivatsa Srinivas, a co-instructor at the IIT Madras online B.Sc. degree program. We are going to look at the hypothetical dataset discussed before where we had the list of cities Mumbai and Chennai and the brand preferences in different cities across three brands A, B and C. This is what the hypothetical dataset look like. We have the list of cities and the list of brands. The objective of this exercise is to understand whether different cities have any impact on brand preferences. That is the null hypothesis in the chi-square test of independence is that the two categorical variables are independent and the alternate hypothesis is that the two categorical variables are non-independent. That is what we try to establish with this case. We need to perform this test by importing certain packages. We need to require the following packages NumPy, pandas, and scipy and within scipy we require the stats package. And since we are performing this exercise on Google Colab, I have uploaded the file to Google Colab and then I extract the CSV file. This is what the file looks like. A part of the file will look like this. The first step in the chi-square test of independence is to construct the contingency table. We have a nice functionality called crosstab with the pandas which will help us do. Across cities and brands, we construct the contingency table. The contingency table will look like this, where we have the cities and the brands and this is from the given dataset. This is called the observed frequency. To perform the chi-square test of independence we need to compare this observed frequency against the expected frequency. That is we are trying to use a certain sample and then comment on whether the categorical variables are independent or not. We use a sample and then comment on the population. To do that, we need to first construct the expected frequency. Only when we construct the expected frequency and we compare the observed frequency against the expected frequency. We have the observed frequency table here. The next step is to construct the expected frequency. But before we do that, we need to know how to access values within this table here. Contingtab of A will give us value corresponding to brand A. We have 165, 279, and 444. Contingtab of A of Chennai will give us 165 corresponding to brand A and city Chennai. And contingtab of all will give us the total sum or the total observed frequencies. There is also another command which we will look at which is contingtab dot transpose which will generate the transpose of the given table. Instead of city and brand, we have interchanged it to the brand and city. We require this command to access certain values which I will show you as we move along. Now the objective is to calculate the expected frequency. We first generate the list of cities which are Chennai and Mumbai. We have this data frame in here with the city. The unique values in the column city will give us the list of cities. And similarly, the unique values within the column brand will give us the list of brands. Once we do that, we create an empty dictionary called exp1 and then run a loop over cities and brands. Within the cities loop, we create another dictionary exp2. And finally, this exp2 will help us calculate the expected value corresponding to a city and a brand. This contingtab dot transpose of I will give us the value corresponding to the particular city. We have the city here and the value i is corresponding to Chennai. The value of all here is 403 and the contingtab of j of all is corresponding to the brand. The brand here happens to be A is 444. We have 403 into 444 divided by 980 which will be the value of Chennai in this case. Let us verify for one combination that you are convinced. We have 403 into 444 divided by 980 which happens to be 182.58. As we run over this loop what we store is the values of the expected frequency within this dictionary exp1. When we run this exp1 what we obtain is corresponding to Chennai A, Chennai B, Chennai C, and so on. For now, we are done with calculating the expected frequency. The next step is to calculate the value of the chi-square. And the chi-square value is calculated as the observed frequency minus the expected frequency of the whole square divided by the expected frequency. And this needs to be sum across all combinations of brands and cities. We run a loop over cities and brands and then we calculate the value of a particular observed value minus the expected value of the whole square divided by the expected value. And this needs to be summed across every combination. And this is how the chi-square calculated value is generated. As you can note, the chi-square calculated value turns out to be 7.009. You can go back to the earlier lecture and refer that the chi-square calculated value is indeed the value shown in this case. Now, the degrees of freedom are the length of cities minus 1 into the length of brands minus 1. We have cities to be 2, which is 2 minus 1, and brands to be 3, 3 minus 1. Therefore, 2 into 1 will be 2. Now, we use the stats package to calculate the tabulated value of the chi-squared. We have the level of significance to be 0.05 and we use this stats dot chi2 dot pdf to calculate the tabulated value of chi-squared. And when we do that, we update 5.99. You can go back and refer that the tabulated value is indeed 5.99. Since the calculated value is greater than the tabulated value, we are going to reject the null hypothesis that the two categorical variables are independent that is what we conclude from this. Instead of constructing the contingency table and performing multiple steps, there is a shortcut method to this chi-squared test of independence in python. In that, we first create a NumPy array as follows. We had created the contingency tab using the crosstab functionality of pandas so that contingtab dot transpose of Chennai will give us the values corresponding to Chennai. And the contingtab dot transpose of Mumbai will give us the values corresponding to Mumbai. We only consider the first three values in this case that is corresponding to brands A, B, and C. And we then have the values corresponding to Mumbai brands A, B and C. And once we create this contab, we can use the stats dot chi2 underscore contingency to generate the chi-squared test results. This becomes very straightforward in the fact that you are using just one command to generate the chi-squared test results. As you can see here, you have directly calculated the chi-squared value to be 7.009 and you also update the p-value, which is 0.0300, the degrees of freedom, and the observed frequency. With a single command, you can update all these values. Now we have the level of significance to be 0.05. Since this 0.03 is less than 0.05 this is a low p-value for rejecting the null hypothesis. Therefore, we can conclude that the categorical variables are not independent. If we can go back to the chi-squared calculated value, which was 7.009, we can also calculate the p-value in the following manner. We have stats dot chi2 dot CDF and the chi-squared calculated value and the degrees of freedom. 1 minus this value will end up giving us the p-value. This p-value turns out to be less than the level of significance which is 0.05. Therefore, we end up rejecting the null hypothesis. This is how you implement the chi-squared test of independence in python. Thank you.