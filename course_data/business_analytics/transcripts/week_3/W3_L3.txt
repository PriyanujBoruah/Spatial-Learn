Welcome to this session on drawing inferences about the association between two categorical variable. In the previous session we had seen how to quantify association between two categorical variables through an application of conditional probabilities. Let us extend that discussion and. Now focus on drawing inferences about the association between the variables. And right. Now we are limiting our discussion to association between two categorical variables. So, let us take an example let us take this example of brand preferences let us say that there are three brands and there is brand A brand B and brand C and let us say that there are different preferences among the brand A brand B and brand C in different cities. And this data let us say is collected from a survey that was conducted in two cities Mumbai and Chennai when we ask them what brand do you prefer? So, 279 people in Mumbai said that they prefer brand A. 73 people in Mumbai said they prefer brand B 225 people in Mumbai said that they prefer brand C. So, totally 577 respondents and this was the breakup of their brand preference. 403 people were surveyed in Chennai and their preference for brand A and B and C is in the second row all right. So, out of the 980 people who were surveyed 444 said that they prefer brand A 120 prefer preferred brand B and 416 preferred brand C. Now we saw analysis of this here you notice that there are two categorical variables which are the two categorical variables? There is one variable in the columns which is the brand Columns brand A brand B and brand C those are the columns. So, there is a column variable column variable is the brand and the row variable is the city row variable is the city. So, the city is we can call city as our exponentially variable and brand preference as our response variable. So, there are two variables and if you notice both of them are categorical Mumbai and Chennai are the categories of the variable called city. Brand A brand B and brand C are the categories of our variable brand or brand preference. So, now we want to infer about the association between the two exponent two categorical variable. So, we essentially know how to summarize this data by calculating what is marginal probability and joint probabilities do you recall that what was marginal probability? What was joint probability? We saw if you recall we said whatever is in the margins is called marginal probability. So, 577 divided by 980, 444 divided by 980 what does 577 divided by 980 means it is the probability of randomly selecting a respondent from Mumbai city. 444 divided by 980 is the probability of randomly selecting a person who prefers brand A. So, those were marginal probability. Now do you recall what was joint probabilities? You go back to that session and understand the definition of joint probabilities joint probabilities is somebody are respondent being from Mumbai and preferring brand A. Somebody who is from Chennai an she prefers brand B that will be the joint probability of definition. So, essentially we wanted to ask a question whether brand preference is associated with the city? If the brand preference was not associated with city the responses would have been similar right with responses would have been similar. So, we are asking a question, are these responses similar? Are these responses similar? So, we want to use statistical independence statistical dependence for this. So, So, from the conditional probability discussion you remember that we said the categorical variables are statistically independent. If the conditional distributions for them is identical for each category that is what I said here if the responses are similar to each other similar to each other which means that the conditional probabilities are similar what what what would that table look like? That table will look like something like this. So, if we had a third city called Delhi and we get something like this. So, we we surveyed thousand people in Mumbai we surveyed hundred people in Chennai we surveyed 250 people in Delhi and this was their brand preference but look at the rows 44% of Mumbai residents prefer brand 14% of Mumbai residents preferred brand B 42% preferred brand C in Mumbai. But the proportion was same in Chennai and Delhii. 44% from Chennai also preferred brand A, 14% from Chennai also preferred brand B 42% of Chennai also preferred brand C. So, this 44%, 14% and 42% was the same similarly for Delhi 110 out of 250. So, 44% preferred brand 35 out of 250 which is about 14% preferred brand B 105 out of 250 which is about 42% preferred brand C. So, the proportion did not change proportion did not change. So, in such a case we can say that the two categorical variables are independent two categorical variables are independent and we can conclude that really brand preference does not seem to be dependent on cities. You go to any cities 44% approximately 44% people prefer brand A Approximately 42% people brand prefer brand C and brand B gets the least preference out of these three brands. Irrespective of the city that you pick but this was this was still based on the data that we have collected this was still based on the sample of 1000 people sample of 100 people sample of 250 people in each one of the cities. So,I mean before we go there you also remember the discussion that we we said that the statistical independence is actually a symmetric property. So, if a brand preference is independent of city, city is also independent of brand preference. So, if you actually calculate the proportion for columns here we calculated the proportion for rows. So, 100% out of 100% respondents 44% prefer brand A 14% prefer brand B and 42% preferred brand C this was the row proportion. If you calculate the column proportion even that is going to be same right even that is going to be same. So, that is going to be the same that tells you that statistical independence is actually a symmetric property but as I said this is based on sample data what about the population? Can I generalize these results? can I generalize these results and say that this independence will actually apply to the entire population. From the sample of 1000+100+250 across the three cities we seem to think that brand preference is independent of the cities does the conclusion extend to the population? Which is essentially inferencing can I infer about the population from this sample in that case simply looking at conditional probabilities may not be sufficient we may have to look at something more. So, can we draw inferences about the population from this single sample from this single sample of 980 respondent this single sample of 980 respondents. I have collected a single sample 980 respondents 577 from Mumbai 403 from Chennai. Can I conclude about the entire population who prefer brand A or brand B or brand C in these two cities by looking at only this sample that is the that is the objective of this session. So, how are we going to do this? We are going to do this by testing hypothesis obviously that is what we have been doing for inferences. Remember from from your BDM course. How do we infer about the population? We infer about the population by running a hypothesis test. This is a special hypothesis test because it has a very different test statistics. So, what is the hypothesis? The hypothesis is that the categorical variables are independent it is always the no effect null hypothesis. Now null hypothesis is always the no effect null hypothesis. Now hypothesis is these two categorical variables the brand preference and the cities are independent no effect hypothesis. Alternative hypothesis is no no they are not independent they may be dependent for that what we are going to calculate observed frequencies and expected frequencies. Observed frequencies come from the sample expected frequencies are going to be calculated assuming that the null hypothesis is true. Assuming that the variables are independent what frequencies do I expect? What frequencies do I expect Now I am going to do this indirect validation of my null hypothesis or not by comparing the observed frequency with expected frequency. Now let us let us do this and calculate the test statistic. So, what is what is the observed frequency? Observed frequency directly comes from the sample these are the observed frequencies 279, 165, 73, 225 these are the observed frequency. 225 people really in Mumbai prefer brand C, 47 people in Chennai actually prefer brand B this is actual observation. So, this is observed frequency 165 is the observed frequency. 279 is the observed frequency. Now let us calculate the expected frequency. Let us calculate the expected frequency. How is the expected frequency going to be calculated? It is going to be calculated as the product of row total into column total. Row total into column total divided by the total sample size let us calculate this. So, how do you calculate the expected frequency? How do you calculate this 261.4? This 261.4 is calculated as row total which is 577 577 multiplied by column total which is 444 divided by 980 total sample size. You can verify that that turns out to be 261.4 how did we get this 70.7? This 70.7 was calculated as row total, row total was 577 multiplied by column total column total is 120 divided by 980. How did we calculate this 171? 171 was calculated as row total which is 403 multiplied by column total which is 416 divided by total sample size which is 980. This is how I calculate the expected frequency. This is a calculated this is how I calculated the expected frequency. 279 is the observed frequency 261 is the expected frequency. Now I calculate my test statistic which is called the chi squared test statistic. The chi- squared test statistic is calculated as summation of the observed frequency minus expected frequency squared divided by the expected frequency. So, let me let me do this let me do this just to show you 279 and 261.4 observed frequency and expected frequency how are we going to calculate the Chi squared for that cell. 279 minus 261.4 whole squared divided by 261.4 261.4. So, this is the first cell right observed frequency 279 minus expected frequency 261.4 square it divided by the expected frequency plus summation sign is plus the second cell what goes in the second cell? Second cell is 73 is the observed frequency 70.7 is the expected frequency 70.7 is the expected frequency squared divide that by the expected frequency plus the third cell. 225 is the observed frequency 224.9 224.9 is the expected frequency. So 225 minus 244.9 square this whole numerator divide that by 244.9 is the third entry. Similarly for this cell this cell and this cell. So, +165 is the observed frequency 182.6 is the expected frequency 182.6 is the expected frequency divide that by 182.6. And we do that for the remaining two cells and the summation of all this all of this is going to be called the Chi squared test statistic Chi squared test statistic. Now what is going to happen if this expected frequency is going to be very close to the observed frequency if the expected frequency is going to be very close to the observed frequency what will happen? we will get very small numerator we are going to square it we will square it essentially to remove the negative signs. If the expected frequency is very close to the observed frequency the numerator is going to be fairly small and therefore the value of the test statistic is going to be smaller. But when am I going to get expected frequency close to the observed frequency when am I going to get that when am I going to get that? I am going to get that So, I am going to get this observed frequency close to the expected frequency only when the null hypothesis actually is true only when the category will be able to be independent only when the categorical variables are independent. So, when the null hypothesis is actually true the expected frequencies and observed frequencies are going to become close to each other and the test statistic is going to be relatively small. However if the null hypothesis is actually not true then for at least some of the cells the gap between the expected frequency and the observed frequency will be quite large and therefore that will result in a very large value of the test statistics. So, how do I decide whether the hypothesis is true or not? Simply by looking at the test statistics. If the test statistic is larger in value that gives me evidence that the null hypothesis may not be true and therefore should be rejected and vice versa. So, essentially a large value of test statistic is actually evidence against the null hypothesis. It is actually an evidence against the null hypothesis. For Chi squared test statistic you actually need degrees of freedom degrees of freedom is actually calculated as row minus 1 multiplied by column minus 1. For example how many rows there are two cities. So, the number of rows is equal to 2, r equal to 2. In our example therefore r minus 1 will be one. How many columns there are three columns for three brands and therefore C is 3, C minus 1 will be 2 and therefore degree of freedom for our test will actually be one multiplied by two row r minus 1 will be 1, column C minus 1 will be 2. So, 1 multiplied by 2 is 2 there are 2 degrees of freedom for our Chi squared test and we are going to get our Chi square test from the table and we are going to calculate Chi square test calculate Chi squared value using this equation. Compare the two and decide whether my Chi square value is large or not. So, for our for our brand preference example it turns out that the calculated test statistic turns out to be 7. So, this this turns out to be 7 calculated value calculated value turns out to be 7. What is the tabular value for two degrees of freedom at 95% confidence our tabular value of test statistic turns out to be 5.99 clearly the calculated value is bigger than the tabular value. Therefore we reject the null hypothesis. We reject the null hypothesis and conclude what was the null hypothesis? That the null hypothesis was that the categorical variables are independent we reject this null hypothesis and therefore say that brand preference does depend on the cities. If you go to different cities people are going to have different brand preferences that is our conclusion at 95% confidence. That is our conclusion at 95% confident which means that if somebody wants to be 95 somebody wants me to be 95% confident I will say that cities do impact brand preference they are not independent and I am saying this with 90% confidence 95% confidence. What if somebody wants me to 99% confident. What if somebody wants me to be 99% confident. If I want to be 99% confidence the alpha value turns out to be 0.01 and the tabular value increases. Tabular value goes up from 5.99 to 9.21. Now comparing 9.21 with 7 suddenly the 7 does not seem to be large value. Since the calculated test statistic is smaller than the tabular value of the test statistic I end up not rejecting the null hypothesis. What do I mean by not rejecting null hypothesis. I cannot reject the null hypothesis and I will conclude that brand preference does not depend on cities. Earlier when somebody wanted me to be 95% confident I concluded that brand preference changes with cities. If somebody wants me to be 99% confident however my result changes now I end up saying that those two categorical variables are actually independent. So, it does not matter which city you go to brand preference remains almost same. Now when I am saying this when I am drawing these conclusions when concluding about the hypothesis I am essentially inferencing about the entire population and not only these 980 value that we have collected from the survey. So, now our results are more generalized. Earlier when we looked at the conditional probabilities we could say only about the sample we could say from the sample it appears. Remember that conditional probability example was about possibility of what was about the MBA admissions given to per male and female candidates. Now we are talking about the entire population and not only the 980 values that we have collected okay not only the 980 values that we have collected. So, that is we drawing inferences about the association between two categorical variables using a Chi squared test of independence. Let us end the session here.