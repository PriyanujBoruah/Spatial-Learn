Welcome to this course, Business analytics. In this tutorial, I will help you build a simple linear regression model in Python. We will use the same data set which was discussed in the course lecture. Let us start. First, we will start our Jupyter notebook. So, I will be using Jupyter notebook. I will be using this folder location to do all the operations. So, Jupyter location. Now, I will create one notepad file, python 3. I will give you the name, say SLR model. Before we start the coding part, let us identify, what are the building blocks of this model? First, we need to import relevant data and pre-process and prepare those data to be used for the modeling exercise. So, we will create one markdown or the shortcut we can put escape M. So, here we will do import data and prepare. And the second step will be, I will fit a simple linear regression model to this data. Escape M; then we will put fitting an SLR model. And finally, we will be showing the output of this model. Then again, escape M and put output. Now in Python, we also need to import relevant libraries, and that is the first block of this code. So, escape above, then escape below. So, to insert a column above the cell escape A, if below escape B. Now, import relevant libraries. Now, what are your libraries relevant for us? For working on the data, data preparation, we will be needing Pandas. Pandas is similar to your Excel notebook Excel spreadsheet. So, whatever the facilities Excel spreadsheet has, those things you can use you can do in with pandas libraries. So, we will have a next is for building the model. We need to work on these arrays like x and y is the response variable and the predictor variables for that you really need NumPy, and third, we will need a library for visualization. For example, to plot the scatter plot. So, we will need Matplotlib fodder. So, we will import pandas as pd. This pd is the alias for pandas. If we do not use pd, every time we have to keep writing this Pandas dot something, pandas dot something else like that. So, it is the pandas we can use pd dot say create a data frame, pd dot read CSV so on. Import Matplot lib dot Pyplot as plt, and the next thing is that whatever the visualization we will be creating on Matplotlib it should be displayed inline. It should not create a pop-up. So, we use percent Matplotlib inline. Now next, we will import the data. So, this is our data heaters. This is in CSV format. So, we will be importing that. So, we have created steps for pandas, df is equal to pandas dot read CSV, and we will be needing this folder location. Here is one important thing in the address line, it has this backslash but in Python, they only consider this front slash. So, we have to change this thing. Then we will have our folder, Hitters1 dot CSV. Now we want to print that. So, this is your file. But remember one thing, since we have only 30 rows. So, this means data is not a problem. But when you are working with big data, displaying the entire data frame will be problematic; your system will hang if it occupy a lot of space. So, that is why we use to display. We just want to see how our data looks like on this data frame. So, for that, we can just create the first 5 or 10 rows. So, we will use this head function by default. It will bring only 5 rows. If you want to bring the first 10 rows, then just put 10. Next, yeah, so next, we have to demarcate what is my response variable what is my predictive variable. Okay, so we have to mark the response variable and the predictor which is my x. To do that, we will put x is equal to from this data frame. We have this price. Price is my predictor. So, this is the first column. In Python, the column number starts from 0, so it is not 1234. It is 0123. So, in a column first, in Python is column number 0. So, df dot ilocate all rows and first column, and we need the values in that column. Similarly, my response variable is df dot ilocate all rows and the second column, dot values. So, I can put x, y. We will print. So, we have two arrays. Next, we want to get. We will see this scatterplot whether we have a linear pattern or not. If we do not have a linear pattern, then we cannot use a simple linear regression model. We do not need transformation. What is transformation? That you will learn in week 5. Now, we need to check whether there is a linear pattern between x, y. For that, we will be using Matplotlib, so, pld. You can see this Pyplot pld already have merged with plt Matplot with the Pyplot. So, we will be creating one scatter plot from there. Now plt dot for the shortcut you can put you have all the functions available in the plt is available to you. So, we use scatter plot scatter. So, we need x and y. This is your scatter plot. So, here is one observation you might have, this is not entirely a linear pattern, per se. It is showing a linear pattern. You might also argue that this vertical pattern. So yeah, in practice, you would not have, I think a, data, which exactly follows a linear pattern. So, what you can do if you are not satisfied with the linear pattern, you can actually transform the data so that it looks like linear. So, the transformation I would not go deep into that but I will give you a short overview of this transformation later in the second part of this tutorial, right. So, right now, we just simply fit a simple linear regression model like how I did in this lecture. Now, next is fitting a simple linear regression model. Now, if you have a single feature, you have to reshape your x to minus 1 to 1. This is required. I think it is for indexing purposes you can search our Google why this is required; otherwise, it will show an error. So, the first is to reshape your data use using array dot reshape minus 1, 1. If your data has one feature that I will show. So, to fit the model, we need to import sci-kit learn. So, those that sci-kit learn will import here in the import relevant libraries, okay. From sklearn dot linear model import linear regression. Now, this is my one functionality, one method, one object, sorry. Now we will create an instance say regressor is equal to regression. This we have created one instance okay. We have created one instance. Now for this instance with this instance, we will fit our model x and our data x & y to build a model. So, regression dot fit, we will fit in x and y. Again we mentioned that you have to use this reshape for x. x is your feature okay. Once you know my model is ready, okay. Sorry, we have run this code. Now we can put linear regression. Now, we will display the output of this coefficient intercept and r-squared—three things we need to put. So, we will put print regressor dot coefficient then put regressor dot intercept. You can verify whether these values are matching to search values or not. So, finally, we need to bring the r-squared value. Now, for r-square vale again, we have to import the relevant library for it. Now, this r-square again is on sci-kit learn. We have to import that r-square functionality from sklearn dot matrix import r2 square. Run it. Now, to bring the r-squared value, we need two things. First is your actual observed way, and there is the predicted way. So, the predicted way comes from our model, which we have built just now. You have to pass on the x value then from this model and the x value what my predicted y value is. So, y pred is equal to regressor dot predict x dot reshape. So, we can print what y pred is. These are y predicted values. Now, my r2 score will be between y and y pred. This is my r-square value. You can match whether this is the same as what satisfies. So, this is a simple linear regression model. Now, we will move on to the second part. In the second part, we will discuss briefly about transformation. So, for that, we will come to this scatter plot matrix. I have previously mentioned that you can also argue that this is a slightly cervical pattern. So, in this case, what I can do to make it linear so that I can improve my model accuracy, but remember transformation does not necessarily always increase your r-square value because it might not be required, and also, you have proper guidelines like what kind of transformation you should use for a particular pattern, that will be discussed in a week five. So, here it is like you to take help up of (())(16:57) circle which is discussed in week 5. So, we will be using some transformation here before we go for transformation; I will just demonstrate what is the effect of a transformation. So, this is your data you can see we can plot a scatter plot matrix. This is your original scatter plot matrix. So, we will fit a trendline here, form a trendline will display equation on chart r-square value. This is my original stuff. Now say I want to put a square root of y, square root demand. So, S-O-R-T demand. Now, if we plot a scatter plot between these two columns, these two columns you could see now it is a lot better. Just put one trendline here, equation form a trendline plus the equation on chart and display r-square value. Now, if you compare this to r-square value has improved but remember you can one thing improve r-square value is not necessarily always been a better fit. You have some other factors that need to be accounted for. But here, since the pattern is quite better compared to the first one, the r-square value is improved. Now we use this transformation here. Now what transformation you will use, y new is equal to np dot sqrt y, y new. This is the y-squared value. Now we will use we will build this model again, we will see what my r-square value is. We will keep a new name regressor 1, regressor 1 we will put it as a y new—Regressor 1, y pred 1, y new, y pred 1. Here y pred 1. Now can compare what is this data is matching whatever I just now I have shown you. Then you can see the r-square value has improved. So, this is your transformation again. I am not going into detail of transformation, and this thing will be discussed in detail in week 5. And the last part, I will just show you how in practice, the machine learning model is deployed. When you will build a model with big data, you split the data into two-part training and testing. You build a model on the training set, and we will predict the testing. So, then you will find how accurate your model is. So, here we will do here. Now again, with this, we have to get the functionality from a sklearn. So, we will demonstrate here the train test split. For that, again, you have to import relevant functionality from this sklearn. So, we have from sklearn dot model selection import train test. Then we create five arrays and from this functionality. So, we have x train, x test, y train, y test is equal to the train test split. Then we have x (())(23:12), and we have y. And how much we will create 20 percent as a testing data. So, we have a test size is equal to 0.2, and we have randomly we will pick this data. This is 0. Now we have y pred is equal to create a model. Now we will define a model; model fit is equal to linear regression, then model fit dot fit x train and y train. We will build a model based on this data set. Then we will predict x test to get y predict. y print is equal to model dot fir dot predict. We will x, x test okay. Then we have y pred. Now we display the r-square value. R-square on y test and y pred. We have now you can see r-square value has come down. This is because we have just 20 percent of 30 data points, that is 6 data points. More data points, more accurate your model will be, and in practice, we will have millions of data, and your model equation will improve. So that is all for today. If you have any doubt, you can put it on the discussion forum. Thank you.