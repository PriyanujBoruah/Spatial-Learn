So, let us take a look at this from a sample data that we have for this relationship. So, let me stop sharing slides. I am stopping the slide share and going to the excel sheet, going to the excel sheet. So, here is the data. So, these are the different prices offered in the, these are the different prices offered in the market for this experiment. And for this particular price, the corresponding demand was recorded, when the price was 3, the demand was 7479, when the price was 4, the demand was 7095, when the price was 5, the demand was 7633 and so on, when the price was 29, the demand was 224. And if you simply plot the relationship between price and demand, it looks like this, it looks like this. And it is not very difficult to, to see the kind of relationship, we can actually say that the relationship is going to be, the relationship is let me select a nice one. So, the relationship looks something like this, which is, which is clearly for the constant elasticity relationship. So, the relationship clearly seems to be of this type, where D is equal to C into P to the power of negative epsilon, where epsilon is the elasticity. So, with this, we have already seen, this is clearly nonlinear, you really cannot apply linear relationship, linear regression to this. To apply linear regression to this, what did we do? We took a log of both sides. So, log of both sides, even though we say log I have taken natural log here. So, that is what we had done in the slides. So, I can change this also. So, let us call this as, how do I get out of this. So, I convert this and I say that this is natural log, this is also natural log and I have anyway use the ln function. So, I have simply taken the log of price, I have simply transformed, I have simply transformed the log of demand. So, now, going back to the PPT, I have a log of demand, I have a log of price. And I will now try to use a simple linear regression model to estimate the value of log of C which is going to be my Y intercept and negative epsilon which is going to be my slope. So, going back to excel, these are my transformed values, these are my transformed values, these are my transformed values. Now, if I plot the relationship between the log of price and the log of demand, I expect that relationship to be linear relationship, I expect that relationship to be linear relationship, let us try to see whether it is really a linear relationship, I have plotted a, I have plotted a scatter plot of this. I have plotted a scatter plot of this and clearly, when I take a log of this, you can, you can see that these are the log values these are the values that I have used and the, the plot looks nicely linear, I have also plotted the linear trendline and I have also plotted the R squared, remember what was R squared? From our previous discussion, what was R squared? R squared was called the coefficient of determination. So, what does this.8191 indicate?.8191 indicates that this relationship between log of price and log of demand, this relationship, this linear relationship is able to explain 81 percent variation in the values of log of demand 81 percent variation capability. So, this model, this simple linear regression model is able to explain 81 percent variability in the response variable, my response variable is log of D. So, therefore, this model looks to be a good model. Now, let us formally run a regression on this. I hope you are okay, with this discussion so far, you are okay with this discussion so far. So now I will select these values, let me select this, this thing also. Let me go, let me go to the function. Where was that? Under data, under data, once again I am using a different computer. So, let me go and get my, let me go and get my solver add in I will go to add in, so I will say, go, and I will ask Excel to add an analysis toolpak on my excel. I do not have, I do not need to add, solver add in. Then, I will go to the data analysis toolpak in excel. I will go to the option for regression. Where is, where is my Y range? My Y is the log of demand, this is my Y range, this is my Y range. Where is my X range? My X, my explanatory variable is the log of price because of the transformation. So, this is my. Do we have labels? Of course, yes, we have labels. Output, where do I want to put the output? Let us put it somewhere, so that it does not disturb us. Where do I put it? Let us put it here, let us put it here. And, now, I am trying to fit a linear relationship between the transformed variable, between log of price and log of demand. In the previous session, we had simply run a linear regression for the actual variables price and demand. So, now, this is the regression output, let us interpret the output the same way that we had done it in the previous session. So, what is multiple R? Multiple R is the coefficient of correlation, coefficient of correlation 0.9 even with the transformation, even with the transformation the association, the coefficient of correlation is about 0.9. What is the coefficient of correlation? The number indicates the strength of association and the sign indicates the sign of association. So, this is going to give me 0.9 only the strength, it is not going to give me the direction. Direction can be obtained by actually getting the excel function. What is that excel function? So, I will say correlation between this array, between this array and then this array. And, that correlation is going to be the same value with a sign also, with the sign. Negative indicates this, the direction of association which means that as the log of P increases, the log of demand decreases. So, a negative value tells a sign of R, tells you the direction of association, the number indicates the strength of association 0.9 is fairly close to 1. So, the association is fairly strong. So, 0.9,.8191, we already know what that means 81 percent of the variability in the response variable is explained using this regression model. What is this standard error? Standard error is the standard deviation of the error terms. Remember what we said in the simple linear regression. The error terms, the error terms for regression. So, how do you interpret this? How do you interpret this.60?.60 is the standard deviation of the error term. Remember for the regression, we said that the error terms are normally distributed with a mean 0 and standard deviation sigma of epsilon and that sigma of epsilon is this.6076, the standard deviation of the error terms. Now, let us look at the ANOVA table of the regression which tells us whether the regression is significant or not. We have interpreted what the degrees of freedom mean, last session we did that. We know what the sum of squares mean, sum of squares of regressions, sum of squares of residuals either you call it residuals or you call it error either you call it regression or you call it model. So, it can be either SSM which is the sum of squares of the model which is this 148.50 or it is also called the sum of squares of regression. Sum of squares of residuals is also called SSE sum of squares of, sum of squares of errors which is 10.70 and we know how degrees of freedom are calculated we have a total of 31 observations. So, total degrees of freedom is going to be 30 minus 1, 31 minus 1, which is 30. In a simple linear regression, we are actually estimating two parameters beta naught and beta 1 and therefore, two parameters to estimate. So, two total degrees of freedom will be 2 minus 1, therefore 1. How do you calculate the mean sum of squares? This is the total sum of squares. So, this means some squares. Mean some of squares is going to be the total sum of squares divided by degrees of freedom. So, 48 is calculated as 48.5 divided by 1, this.369 is calculated as 10.70 divided by 29, 48.5 divided by.36 is going to me the F statistic. So, this is the F statistic and what is the hypothesis, the hypothesis we are testing using this test statistic is the overall significance of the regression. Therefore, the null hypothesis is always the no effect hypothesis. Therefore, the null hypothesis for this test is that the regression is not significant, whatever you have done, whatever, whatever simple linear regression model that you have tried to fit is not significant and that is your null hypothesis. Alternate hypothesis of course, will be that linear regression model is significant. Now, the value under significance F is the P value, is the P value for this hypothesis. So, P value seems to be of the order of 10 to the power of negative 12. So, we know what happens if the p value is that small, you always compare P value with alpha. Alpha is usually 0.05. If you do not recall what the alpha value was, that was used, you can always go back to your regression, you can always go back to data regression. So, see, something that we did not edit was the confidence level, confidence level was 95 percent, if you can see in the dialog box, the confidence level was 95 percent therefore, the alpha that was used for this test is anyway 5 percent. So, compare that 0.05 with a P value of 10 to the power of negative 12. And you will clearly say that the null hypothesis has to be rejected. So, what is the overall significance test? Using the F statistic here, the overall significance test says that the null hypothesis that the regression is not significant has to be rejected, therefore whatever we have done here trying to fit a linear regression, trying to fit a linear regression between the log of demand and the log of price, that makes sense, that is statistically significant. Now, let us look at the individual parameters. How do you estimate the intercept? The intercept value turns out to be 11.23. What is the P value for this? There is a t statistic, so, P value, sorry the coefficient value 11.23 is an estimate of beta naught. So, let us call this as b, b naught. So, let us call this as b naught, we really do not know the beta naught value. Beta naught value will be known only when you know the entire population of values, we only have 31 observations. So, we do not know we have a small sample of 31 observations. So, we cannot estimate beta naught perfectly, we can only estimate a sample value, let us say b naught. So, this b naught can change and so, there is a standard error for that also, standard error for estimating b naught is.36, the t statistic is 31.18 and the p value is 7.39 E to the power of negative 24. What does that mean? If you recall, let me do that in the PPT here, let me do that in the PPT here. Let me include a new slide. And so, what is, what is this test? So, you have a regression equation which says Y or the expected value of Y, expected value of Y is beta naught plus beta 1x. So, this beta naught has to be estimated. This beta 1 has to be estimated and you only get sample values. So, at best you are going to get beta, beta naught estimated using b naught, beta one estimated using beta 1 and that is, that is the best you can get. Now, since this is the sample value, this is the population value, you can actually check the hypothesis if beta naught is 0, against the null hypothesis that, against the null hypothesis that beta 1 is not 0, beta 1 is not 0. Now, what is going to be the test statistic, it is going to be a t test. Test statistic is going to be the sample value. What is the sample value? Sample value is beta naught minus the hypothesized value. Hypothesized value is 0 divided by the standard error, standard error of estimating beta naught. So, from the excel sheet, let us stop this slide, go to excel, go to excel. And these are the values 11.23 is b naught, 0.36 is a standard error, 0.36 is a standard error. So, let us go here. So, if this is your 11.23, this is your 11.23, this is your.36. And, you can confirm, you can confirm that the ratio turns out to be, ratio turns out to be 31.18 and the P value for this hypothesis test is of the order of 10 to the power of negative 24, 10 to the power of negative 24. So, the P value is of the order of 10 to the power of negative 24. Clearly for such a small value of P you are going to reject the null hypothesis and say that whatever the value is, it is clearly not 0. So, I will say that 11.23 is a good estimate, a good estimate of beta naught, I can actually go one step further. Excel actually gives me the range in which beta naught is going to exist. So, here is the range. So, excel tells me that the beta naught can be anywhere between 10.50 and 11 0.97 with an estimated value of 11.23. So, it can be anywhere between 10.50 and 11 0.97, both the values are definitely greater than 0. So, I will reject any claim that this beta could actually be 0 with 95 percent confidence. Since I rejected this claim, I will accept this estimate of beta naught, a very similar explanation for the slope. Slope estimate, which is beta 1 estimate, 1.5, the P value is of the order of 10 to the power of negative 12. So, I have no reason to say that this negative 1.5 is a bad value. Looking at the range, excel tells me that the slope can be anywhere between negative 1.77 to negative 1.23, anywhere between these two values. The lower limit is negative 1.77, upper limit is negative 1.23. And the estimated value is negative 1.5, negative 1.5. And the P value is 10 to the power of negative 12. So, I will actually reject the null hypothesis that beta 1 is actually 0. And like we saw last time, this P value is going to be same as this P value, this P value is same, going to be same as this P value because in the overall test of regression significance, you are essentially checking whether a beta 1 is 0 because if beta 1 is 0, your entire regression collapses and X will not be able to impact the Y values. So, not surprisingly, this P value is the same as this P value. Even though it is done using different test statistics, we are actually testing the same thing. If you are wondering why, you did not get the same value? Well, it is just a matter of how many decimals do you print in the excel, excel cell. So now, you see that 2.75 E to the power of 10, E to the, 10 to the power of negative 12, 2.75, 10 to the power of negative 12, they are the same values. Now, this is about the regression output. Let us go back and interpret and see what that means to our demand price relationship. So, remember, we are going back to excel. What do I, what do I take from here? What do I take from here? I look at the estimates, I look at the estimates. So, 11.23 and negative 1.5, 11.23 is my intercept, negative 1.5 is my slope. Let us go back here. So, what is my Y intercept turns out that this is 11.23 and slope is negative 1.5, negative 1.5. So, what is the value of log of C? Log of C is 11.23. And from here you can estimate the value of C. C will be e to the power of negative 11.23, e to the power of 11.23. Similarly, what is, what is epsilon, which is elasticity? How much is elasticity? Elasticity is 1.5, 1.5. Now, how do you interpret the elasticity of 1.5. Is elasticity 1.5 too large, too small? Remember what is, what we said. Generally, elasticity of less than 1 is a small value of elasticity. Elasticity of more than 1 is usually considered to be a highly elastic product. What do you mean by a highly elastic product? A highly elastic product will fluctuate the demand as the price fluctuates by a small amount that is elasticity. So, as you increase the price, I will correspondingly decrease the demand for that particular product. In elastic products like we saw salt, highly inelastic products, because even if the prices go up, I need salt. Without salt, I cannot taste my food properly. So, that product is a highly inelastic product. So, here we estimated the elasticity to be 1.5. So, we can conclude that if the data looks something like this, let us go back to data. If my data looks something like this. Where is my data? Here is my data. If my data is something like this, it points to a, it points to a constant elasticity model, because first of all, I correctly thought that the relationship is nonlinear, the relationship is of this type. Why did I say that this was correct though because when I took a log transformation, I got a very good fit for the log transformation. I got a very good linear fit for a log transformation. So, when I fit that into a regression model, I was able to explain 81 percent of the variability in the response variable. So, I think this is a good transformation. And therefore, I think this is a good estimate of the relationship between demand and price. So, once again, we have, we have, we have seen the regression output, but remember regression output is valid only when the assumptions about the error terms are, are, are satisfied. What were the assumptions about the error terms? We did that in the last session. What were the assumptions? These were the assumptions about the error terms error terms are assumed to be independent, they are independent of each other. The error terms have equal variances. And the error terms are normally distributed. We have to confirm that these assumptions hold, these assumptions hold and only then can we say that my regression model is actually of statistical significance. So we say that we should be testing these three assumptions, and if these three assumptions are found to be correct, then these are the interpretations, these are the interpretations from the data the demand seems to be highly elastic with a constant elasticity of 1.5. So, let us end the session here, let us end the session here. So, we have seen what is the demand response curve, what is the basic understanding, what is the slope, what is the elasticity, we have seen those things. Then we saw a very linear relationship between price and demand and that was estimated using a very simple execution of a simple linear regression model. We saw a nonlinear relationship between demand and price through a constant elasticity model. Now you, now in today's session, we saw how this nonlinear relationship between demand and price can actually be linearized by taking log, log transformation, and we ran the regression model, we interpreted the regression and then we interpreted back the values for C and elasticity. Let us end the session here and stop with this.