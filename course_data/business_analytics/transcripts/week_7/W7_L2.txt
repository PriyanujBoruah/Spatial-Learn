So, in the last session, we saw how the data about placement is available. So, we had four variables. The academic performance during MBA program, academic performance during UG program, the industry experience of a student, and the extracurricular co-curricular activities ratings everything was rating on a scale of ten. So, essentially, we had reduced the problem to predicting the value of y using x one, x two, x three and x four. So, is this regression then, are we talking about a regression problem, if this were a regression problem, we would have written the expression in a particular way. But essentially we are asking, can these attributes be used to predict whether the student will pick up a job during the placement process? So, essentially are these attributes in any way related to y. So, the answer is it is a regression problem unfortunately, it is not a straightforward regression problem it is what is called as a logistic regression problem,. Why is it logistic regression problem? Because our response variable is a categorical variable, our response variable is a yes, no question. Our response variable does not take continuous values. So, therefore, this problem cannot be solved using regular regression method. So, if we pay attention to our response variable, our response variable is binary. And therefore, we cannot use our regular regression methods nor can we use the regular regression expression. If we had used the regular regression method if this was a multiple linear regression problem, now, what is the multiple linear regression problem? Refer to the previous sessions where we have described the multiple linear regression problem and we had taken an example. If I remember correctly, that example was also from a B school where we had looked at predicting the academic performance of the student. Now, we are going one step ahead, we are saying the academic performance of the student is available. Now, we want to predict the probability that the student will actually get placed. Well, we are not trying to predict the probability, we are actually trying to directly predict whether the student will get placed one or zero. So, if we had used multiple linear regression model, we would have written the expression this way. So, you already know this expression by now. So, y is equal to beta naught plus beta one x one plus beta two x two plus beta three x three plus beta four x four plus that error term epsilon. Where we know that beta zero beta one beta two beta three beta four are the regression coefficients which need to be estimated for the regression model to be good model. And we know what are what do we mean by regression model to be a good model. However, as I said our response variable is binary. And therefore, many of the assumptions of the regression model will not hold and we will not get good predictions if we decide to go with multiple linear regression. Therefore, we are not going to use MLR for this example. So, what are we going to do, we are going to go logistic regression way. So, what is this logistic regression let us proceed towards it in a step by step pattern. So, since we cannot use directly y because y is binary. And it may violate some of the assumptions of MLR can we use probabilities. Now, we are then we are converting this response variable, we are not saying y is equal to one or zero. Now, we are saying probability of y is equal to one what is the probability that the student will get placed? So, essentially we will ask ourselves what is probability of y is equal to one. Now, if we do that, we are essentially converting the response variable. Now, our response variable can take any value from zero to one because probabilities can only be between zero and one. So, let us let us use probability of y is equal to one as our predictor. So, now we are moving away from only zero, one values to any value between zero and one turns out that even that is not a very right wait go ahead. But if we use odds, if we use odds instead of probabilities, then we can even get out of this limit of zero and one. Right now, if we use probabilities as our predictor, we are still limited. What are our limits? Our limits are only between any value between zero and one. If we want to get out of this, then we can use odds and odds are defined as a ratio of probabilities. So, how do we define odds odds of success if the ratio of probability of y is equal to one divided by the probability of y equal to zero. So, what is it ratio of probability y is equal to one to probability of y is equal to zero. So, this is called odds are odds ratio. Odds, they are called odds. Once again, let the definition be very clear. Now, from the definition of arts, it is very clear that odds are not limited to a value between zero and one. Now, if we say that this probability is 90 percent then obviously, the probability of y is equal to zero is zero point one. Because probability of y is equal to zero is one minus probability of y is equal to one. So, if we go that way, then obviously, the odds are ninety nine is to one, we call it ninety nine is to one odds. Now, if this were zero point ninety nine this will be zero point zero one. And the odds will be ninety nine is to one. So, we have essentially removed the condition that would have been imposed if we had used probabilities as our predictor. What are we going to do is we are going to use odds as our predictor. So, how does the equation transform? How does a regression equation transform if we use odds as our response variable? So, generally we do not use odds we actually use log of odds. So, that we get values in the negative side also. So, let us drop the error term for now, this error term let us not worry about it, let us not be statistically precise, let us understand the concept of logistic regression. So, I am going to drop the error term, but that is not a statistical mistake we are dropping it for convenience. So, as we said earlier now, we are going to say that our response variable is not plain vanilla why our response variable is not even probability of y is equal to one because we saw the limitations. Limitations are we will only get values between zero and one. Now, if we use odds, odds are also kind of limited because they will get values only on the positive side. Let us take log of odds log of odds will give us values even on the other side. So, this is the expression that we are going to use for our logistic regression. So, this is the final expression that we are going to use. How does that transform? Then let us make this transformation quickly so, that we understand the probabilities also from this equation. So, let us take the anti-log on both sides. So, odds will be equal to e to the power of beta naught plus beta one x one plus beta two x two and so, on. Remember, we have to be careful about this here, I am assuming that the log is to the base of e. Now, if log has a different base, obviously, this will change. Let us not get into the mathematics of the base of log but be careful about what base you are going to use. And because it dictates the logit regression expression. So, if we use log of odds as our response variable, the odds will be given by e to the power of beta naught plus beta one x one. And we know what our odds? Odds are probabilities and therefore, you can get the expression for probabilities. So, you can actually ensure you can verify that probability of y is equal to one probability that the student will get placed will be given by this expression which is at the bottom of your screen. So, let me repeat that. So, we have a whole bunch of x variables and y variables. We have a whole bunch of x variables and y variables. We said since we have four x variables and one y variables, is it a question of regression?. And then we said since our response variable is binary, we are going to use what is called as logistic regression and not our regular MLR. If this were MLR, we would have written the expression this way. But it may violate some of the assumptions of the MLR. Because your response variable can only take two values. Therefore, we saw whether we can use probabilities, we realize that the probabilities are limited only between zero and one. So, we thought let me take odds. Odds are defined as a ratio of probabilities. We said even odds looks a little odd. And therefore, the general practice is to use log of odds. And that is what the common practice is in the logit regression. So, we said the response variable will be log of odds. And from there we calculate we wrote the expression for the probability and finally, we got the probability of y is equal to one to be this expression. Make sure that you have digested all this mathematics, we are going to show all this in an Excel sheet. So, in this session, when I am discussing logic regression with you, we are going to use Excel. Whereas, when we run the tutorial, we are obviously going to move away from Excel that that has always been our practice. And we will use Python to show you the logistic regression for the same example. But right now, we are going to run this example in Excel. Choice of Excel is a little odd because ideally speaking, Excel does not handle logistic regression very well. So, as you are going to see later, we are going to calculate a lot of things manually does not matter, I like calculating things manually. Because it helps us explain all these steps that we are currently showing on the slide are very chronologically in an Excel sheet. So, what do we run the regression for, we run the regression to essentially estimate the regression coefficients which are the betas we are still interested in finding these betas, these are the betas that we are interested in beta naught, beta one, beta two which are available in the numerator as well as the denominator. So, the objective of the regression still does not change even if it was MLR we were interested in estimating the values of beta naught, beta one, beta two even in logistic regression, we are interested in the estimation of beta naught, beta one ,beta two. Here the objective is different in MLR the objective was minimization of the squared errors if you recall. In the logistic regression or the objective is maximization of log likelihood. What is log likelihood ? it is the log of probability of correct predictions. Now, be very clear, it is not the probability of y is equal to one , it is a probability that this model will correctly predict whether the student will get placed or not. So, it is slightly different and we are trying to maximize the log of this probability. So, that is going to be the objective function that we are going to use once again highlight in the difference between MLR and logistic regression. In MLR the objective of running the regression and calculating the parameters or estimating the parameters is to reduce the sum of squared errors. In logistic regression, the objective of running the regression and estimating the values of regression coefficient is maximization of log likelihood which is the log of probability of correct predictions. Let us see the Excel sheet as I said. Let us see the Excel sheet and I zoomed it up. Now, this is what our data was. And now, let us go to the logistic regression part of this. Let us jump to the data first I have already solved logistic regression. So, you will see all kinds of numbers here. So, this is the data this is the plain data that we had in the previous slide also this is plain data. So, what is the first thing to be seen ? the first thing to be seen are the correlation coefficients. So, which is going to be a matrix and these values are blank, because it is a symmetric property correlation is a symmetric property. So, the correlation between experience and MBA CGPA is fairly weak a negative zero point zero three correlation between UG CGPA and MBA CGPA is quite strong and we have seen it is generally strong. But what we are interested in are the correlation coefficients here because these are the correlation coefficients of response variable with the explanatory variables. So, MBA CGPA is correlated with placement, y is equal to one or zero and the correlation coefficient is zero point six almost, experience and placement is zero point one six UG CGPA and placement is zero point four two and extracurricular and day zero placement is zero point three five so, not so, trivial association among the explanatory variable and the response variable. And ideally we want these numbers to be small, except for this one number. The explanatory variables do not seem to be associated that strongly with each other. For example, this is negative zero point zero seven. So, ideally that is what we want, but I will look at these numbers and say, we are all right we can run this and see what happens. Anyway, right now, the idea is to show you the logistic regression and as I said this is synthetically generated data. So, the first thing that we do. The first thing that we do is to code the expression what is the expression that we are trying to code this is the expression that we are trying to code log of odds beta naught plus beta one x one plus beta two x two plus beta three x three plus beta four x four. So, this is that expression where are my betas? This is where I have put my beta, beta naught beta one, beta two, beta three, beta four. So, I will write my expression here, which is beta naught which is A two and then beta one x one, beta two x two beta, beta three x three, beta four x four these are the values of x one, x two, x three and x four for student number one. So,this is my expression, this expression. I have written this expression in Excel then what did I say? I said calculate the odds, how do I calculate the odds e to the power of this e to the power of this? So, let us let us do that. So, next thing we are going to do is calculate the odds. What are odds? Odds are e to the power of this. EXP is the function in Excel e to the power of this nothing different, nothing new. e to the power of the right hand side. And from there, I will calculate the probability. How do I calculate the probability I calculate the probability that y is equal to one. It comes in here. How do I calculate this probability? So, it is this exponential divided by one plus exponential. And we know that is correct because it is this expression. It is the exponential divided by one plus exponential. So, this is the probability of day one job. Sorry, day zero job. This is the probability of day zero job.This comes from the model. Note that this is the observed value. This is whether the student got placed or not. This is my model predicting whether the student will get the job or not. So, what is the probability that I am actually correct? What is the probability my model predicted that the probability of day zero job is ninety seven percent the student actually got placed. So, what is the probability that I am right, I am right with ninety seven percent probability. Here, I predicted that the student will get a job and the probability is ninety one percent. Student actually got a job. So, the probability that I am right probability that my estimate is correct is 91 percent.Look at this or look at this. Here, I predicted that the probability that the student will get a job, the probability that the student will get a job is only zero point zero zero four. And the student actually did not get a job. So, what is the probability that I am actually right? I am right with the probability ninety nine percent. Because I anyway predicted a very low probability that the student will get a job and the student actually did not get a job. So, the probability that I am right is fairly large. That is how I calculate the probability of correct estimate. This is what I said, this probability tells me the probability of y is equal to 1 this zero point nine seven five one is the probability that y is equal to 1. This probability zero point nine seven five one is the probability that the model predictions are correct. Models predicting correctly. Now, let us take a log of that and sum of the log sum of the log which is the summation of the log, and then we will use this as our objective function. Where did we say this? We said that here, we said that objective is to maximize the log likelihood. Log of the probability that the model predictions are correct. So, this is that log likelihood, this is the summation of all the log likelihood. And using this, I ran the optimization problem saying that this is what I wish to maximize. What can I change? What is this whole problem about this problem is about predicting or estimating the betas. So, I told Excel try to get a maximum possible value of the log likelihood sum of log likelihood by changing what by changing beta naught, beta one, beta two, beta three, beta four. So, these are my estimated values of beta one, beta two, beta three, beta four. That achieves the objective.