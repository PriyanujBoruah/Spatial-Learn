Hello all and welcome to this tutorial on logistic regression. So, today we are going to take an interesting data set and look at the predictions. You all might have encountered this particular thing, you might be getting calls from callcenters asking for car loan or bike loan and so on. So, today we are going to take one such data set, where we are going to predict whether the customer is going to avail a car loan or not. So, without wasting further time, let's load the data set and see how the features are and how the features are looking like and how the target variable is looking like. So, this is the data set. So, we have the following columns. So, let me also increase the size so that it is, the visibility is better. I hope it is better now. So, these are the variables. So, this is the data frame that we have starting with the feature called tier. Tier is nothing but whether it is a tier 1 city or tier 2 city and so on. FICO is a credit score that is predominantly followed in the United States and then comes the Term. So, whether the customer is going to take the loan for 5 years or 6 years and so on and this is the Amount in dollars and then comes the Previous rate. For example, if a customer has taken a previous loan, what was the rate of interest, it could be 5. So, we have some interesting things here called minus 10. For example, if a customer has never taken loan, ideally it should be 0. But what will the model understand is that the customer has taken loan at 0 percent rate of interest. So, therefore, what we have done is we have imputed all 0’s with minus 10 which is far away from 0 percent interest. Then comes the competition rate of interest and the company's rate of interest, then some funds some classification of the customer, then comes whether the customer is going to take a loan for a new car or is he a repeat buyer or is he going to go for a used car. And finally the decision variable is whether the customer accepted the loan or not. : So, let's also print the shape of our data frame. So, we have around 1 lakh 45000 observations and there are 13 columns. We will also describe them. So, for the sake of simplicity, what we have done is we have done all the feature engineering part. So, we have encoded the categorical variables. We have done feature engineering. So, right now you do not see any categorical variables, everything is numerical. And let's also check for missing values, Malolan, so, before we go further, do you want to talk something with regard to the size of the dataset? Yes, so when we have, OK! let's look at it like this. So, in our videos, professor Marathe said, we are going to use Excel, because we want to teach you the computation behind the method values. Now, just imagine if that statement was not needed we are going to model this in Excel, you will have to input a data frame 1 lakh 45000 rows into an Excel. Then built an optimization to find the betas and then do your computation. It will just not be possible for Excel to handle such a huge data frame for this kind of a modelling. So, what we do is instead, we move into tools that are specialized in handling such data frames and that is why we need a tool like Python to do logistic regression or any form of advanced modelling because a data sets are becoming large. OK! And that is why we are doing a tutorial and in fact, in this tutorial, as you can see in our previous tutorial as well, we will be focusing only on how to implement an LR model, logistic regression model in python. We will not be going into the intricate details or what a package does so on and so forth. We will just show you an overview of what to be the general steps followed in creating a logistic regression. And like Swami has pointed out the size of the data frame is the reason why we need tools like Python. Ya, Swami and in fact to add further, there are no nulls in our data frame. There are the categorical variables are already imputed. For example, the categorical variable that you can think of is the car type. So, car type that a person is going to like, let's say a new car, or repeat buyer or a used car whatever. So, that is a, that was actually categorical variable with the car type called car type N new ,R or an U which we are encoded as 100, 010 and 001. So, all the feature engineering, the cleaning up of data, removing missing values, including this value, everything is done. And you are getting a data frame, which has all zeros. Go ahead Swami. Alright! So, as explained before, the data set does not have any missing values. We will also look at the data types. So, everything is either integer or float, which makes it easy for the model to process things better. So, now we look at the distribution of the target variable. So this is pretty intuitive, 77 percent of the people who got the calls from the banking industry, so they say that, well, we do not want the loan, they have rejected it. So, 22 percent. Most of the time when you pick up a call or I pick up a call, I just say, not interested, keep it. So, not number 6, could be seems correct. Yes. So, 22 percent have been turned accepted the car loan... And we are actually interested in that very person, can we model or can someone let us say someone's data is coming in tomorrow, can we say that he will take a loan. So, that is our value of interest. So, again, so we saw certain things were done for simplification. For example, missing value, there are no missing values, the features are engineered. We also have done the train test split. So, far what you have seen is the training data, we will also look at the test data in the coming. You can skip line number 66 that was done for something else. So, you can just delete it off Swami. So, I can. I am deleting this. You can come back to that later, we will come back to that later. We saw the distributions of 0’s and 1’s. So, with that, let's also look at the columns that are available in data frame one. So, we have. 13 columns. 13 columns, starting with tier and ending with accept. So, what I am going to do is, I am going to create a variable called features, which has all variables except the variable called target. Because those variables are the X as you are independent variables, these are going to be your predictors, we are going to use this to predict Y. So, those will be our independent variables and we are putting it in features. Yes, and the target is going to be just Accept. The target variable one whether we want 1 or 0, binary. So, now I am going to create X train and y train. So, far, whatever data we saw is the train data set. So, again, we have done train, there is a test split. So, whatever we had shown you so far, is the training data. So, what I am doing is I am creating two variables called X_train and y_train. And I am going to use the features in X_train, and I am going to use the target column in the y_train. So, let's also print the shape of X_train and y_train. So, if you look at X_train, it has around 145000 observations and there are 12 columns. So, likewise, in the y_train, we have the same number of observations, but just one column which is accept or not. So now. Next, we are going to talk about the test data set. And maybe before we do that let us just give our viewers a refresher, what is a train and what is a test. So, when we talk about train, it is the data set on which we are going to build in the model, it is the dataset on which, from which we are going to identify our different betas for our model. So, that is the train data set. Once you have built a model using the train data set, you will then fit that fitted model with test data set, then compute your measures for the particular model such as the accuracy, position and recall which is what focus for us. So, that is the purpose of a test data set. The test data set could not be seen by that model untill the point where we run it and untill he point that the betas are computed, only after the betas are computed, the model see the test data set. So, that is the purpose of train and test. So, let's also load the test data set. And if you look at the test data set, it has all the variables that the train also had, starting with tier ending with accept. So, let's also look at the shape. Let's, do two things, one, let us look at the shape of test data set. So, test is having around sixty two thousand observation and thirteen columns. We will also look at the distributions of 0's and 1’s. So, it is similar to a train data set, the data distribution is similar to our train data set. Let's, also check for missing values in the test data. Again, fortunately, we have no missing values. Very clean data set, perfect dataset for logistic regression. Yes, so similar to our X_train and y_train, we are going to create X_test and y_test. So, let's also look at the shape of our X_train and y_train. So, we have around sixty two thousand observations, twelve variables under X_test, y_test is having just 1 column and same number of observations as X_test. So, now let us call this package logistic regression from the library sklearn dot linear underscore model. And the next step is to run the logistic regression and then storing the logistic regression in a variable called logreg. Again, we asked Malolan, beautifully explained. You are going to fit the model using X_train and y_train, for which I am going to use this command called logreg dot fit X_train comma y_train. So, you might encounter certain warnings, you can ignore them. So, those are due to the IDE that we are using. The next is to predict the results. So, we build the model using the train data and we are going to predict on the test data which the model has never seen before. And this was the first time that seeing it. Yes. So, therefore the prediction will not have y_test. So, we are fitting the model using X_train and y_train. And the prediction is going to be done only on X_test. So, let's also look at the... Before you print it. Yes. So, may be people can think about that 62426, why is this not a data frame, could be a question. Because it is a vector means. It's just a list of 0’s and 1s, could be a vector and this size will match the size of X_test. So, how many other rows you have in your test data set, for each of those rows, you will make a prediction called y_pred and that will be the number. So, now we have built the model. We have also done some predictions. Now it is time to check how well the model has performed or how well the model is performing for which I am going to import two libraries or two packages. One is classification report, other one is called the confusion matrix. So, we have y test. So these are the actual values and predicted values. So, if I run a confusion matrix using the actual values and the predicted values, we are going to get a matrix like this. And this is called a confusion matrix and it's a confusion basically. So, it is called the confusion matrix. Just make a note of these numbers, we will try to explain this in much more detail using Excel. Then we will come back to our Python sheet and see how all the calculations that we are doing in Excel can be automated through this command called classification reports. Alright, so we are going to take this matrix, 2 by 2 matrix, so 45000, 3300, 8400, 5300 those 4 numbers and put it in Excel and Swami, may be you can open Excel right now. So, in this matrix, we have, it is always 2 by 2 matrix, the first thing. What is it going to say? It is going to have the actual values on your let's say rows, the actual values of 0s and 1, whether the actual is 0 or actual is 1 is going to be on the rows and the column is going to have the prediction whether it is 0 or 1. So, that is the structure of a confusion matrix. Now, what does the number 45323 signifies? It signifies the number of times your prediction was 0 and the actual was also 0. So, cell D5 is actually corresponding to the number of times that your prediction was 0, and the actual was also 0. So, that is what it means. So, if I am telling this, what is the map? the statistical thought process is my prediction is 0 and actual is 0, that is a true negative. So, J5 we are going to correspondingly write the map, the statistical notation as true negative. Now, comes cell number F6, then we have our predictions as 1, and the actual is also 1. So, that is 5335. So, that corresponds to cell K6, we will be telling those are the true positives. When I have predicted it as positive, and the actual value is also 1. So, that is a true positive. Then comes the next definition, then my prediction is 1 and the actual thing is 0. So, that corresponds to the number 3367 cell number F5 which is actually a false positive, you have falsely said it is 1, but the actual is 0. So, that is a false positive. Then comes cell E6 that we have 8401 cases that we have predicted 0, but the actual is 1. So, that is falsely negative value. So, that is a false negative. So, we have told it is negative, which is 0, but the actual is 1. So, that is a false negative. So, a confusion matrix of 45323, 3367 84001 and 53 sorry my bad, 45323, 3367, 8401 and 5335 correspond to true negative, false positive, false negative true positive. So, after this confusion matrix, the next step is to estimate the accuracy, precision, recall, from the given confusion matrix. Which are have, that is how we are going to measure how good our model is. So, let's start with accuracy. So, what is accuracy? It is nothing but the true positive, true negative divided by all the values. So, I am going to mention that here for your reference, true positive, plus true negative. The total number of current predictions that we have for the entire sample, that is accuracy. So, let's also calculate that, true positive true negative plus true positive Positive Divided by everything. the entire sample size or let me put it as entire test size so that we do not have confusion, the entire test size. So, any guess on the accuracy? How well our logistic regression model is going to perform? Around 50,000 as compared to our 62,000 data set. Let us see. It is around 81 percent. Which is good enough for logistic regression model. It is actually a very good number 80 percent, 81 percent. So, next step is to precision. So, precision is always defined based on your problem. And in our case, the problem is to predict a number of 1's, number of loans that will be taken. So, that is where our precision will fall. And what is our precision? According to our definition, it is the percentage of predicted values that were correct. So, I am predicting 5335 values as correct out of the total, approximately 8600 values that I have. So, it is basically a ratio of true positives, divided by true positives plus false positives. Out of my total predictions, how many are correct? For me, for my problem. My problem here is to predict 1, so out of all of my 1 predictions, which is around 8600, 5000 was correct. So, what percentage is that? That is my precision. So, in our case, it is going to be you have F6 divided by F6 plus F5 which will come around 5000 out of 8000. So, it should be a high number. Let us say around 60 percent it is 61 percent. 61 percent. So, you have precision of around 61 percent for our model. Next term that we are looking at is recall. Recall, focuses on the actuals. So, when I have an actual or when I actually have 8401 plus 5333 1's out of which, how much is my model correctly predicting? That is my recall. So, recall percentage would be true positives divided by true positives plus false negatives. Out the total actual 1's, how many is predicted correctly? So, that is recall. So, 5300 divided by total 8400 divided by, that will come to around 13000, 40 percent. So, we call is around 39 percent. So, this is the calculation which we did manually. Yes. So, when you are doing this. And this could, in fact, you can actually draw a panel here with what sir had said, as recall increases precision comes down, precision increases recall comes down. So, that will turn out intuitively this is 61 percent, that is 39 percent. So like you were saying we have done this calculation all manually, can you do it in python? Yes, Malolan, we are going to print the classification report. So, we are interested in this particular thing, which is 1. So, we are interested whether the customer is taking the loan or not for which the precision is 61 percent and then the recall is 39 percent. Look at the calculations. Yes and if you look at the accuracy, it is around 81 percent. So, you are aware of these concepts precision and recall. So, these are covered in the lecture, F1 score is something that was not covered. So, right now, you can treat it as a weighted average between precision and recall. That's all. And one more thing to add here are precision and a recall are defined based on our problem that we are trying to address. Here we are trying to address for 1. So, our precision recall will be 0.61 and 0.39 whereas if we are interested in predicting 0s whether this guy will get 0 or not whether he will not take a loan or not, you will look at a precision of 0.84 and 0.93. So, the precision and recall is always defined based on the problem that you are addressing. So, please remember that and that is what even our video lectures by sir defines. It is the percentage of predicted values that we were interested in and that were correctly predicted. That we are interested in that is correctly predicted. That is the definition for precision. So, he specifically says we are interested in, so here we are interested in 1. So, our precision is 0.61. Let's say we were interested in 0, then our precision is 0.84. This should be very clear, because precision and recall are dependent on your problem, whereas accuracy is always the same. It is 0.81. That is why even our output both says accuracy of 0.81. It does not depend on whether 1s or 0 we are focused on, it depends on the total model. So, that is a very important observation that you should keep in mind. So, do not worry about the support, it is the number of data points that we took for. That calculation, for that calculations. So, let us also look at the probabilities which our model has predicted for each and every observation. So if you print this value, y underscore pred underscore prob, it is going to give you an array, it will have probabilities like 0.1, 0.2, and so on. Let's do one thing, what I will do is I will create a new data frame, I will create three columns, test, prediction and probability. And then see what we have. df3 test y_test. Just check the name of y_test, is it capital y by any chance? This is small y_test. No, it is y_test. df3 is not defined. Okay got it. We did not run the cell. I did not run this. So, I am creating a data frame called df3 which is a empty data frame. I am creating a column called test under this data frame and go to store the results of y_test. Which are the actual. Actual values. which are the actual values in our y's. And then I am going to create another column called prediction or pred. And I am going to store the values of y prep into it. Next we will also have this pred underscore prob, which is the probability that the model has predicted. Let's, print this. So, we have the actual values we have the predicted values and the probabilities. If you take a look at the lecture, professor would have told you something called threshold. For example, if your model is predicting, if your probability is below 0.5, there is a chance that it will be classified as 0. So, that's the threshold, that logistic regression package is using as default. But you can play with the threshold, you can increase or decrease and then look at the results that is going to give you another set of results. But here, we are going to go with a default setting where the threshold is 0.5. Malolan, if you look at this probability, it is 0.1, so it is lesser than 0.5, which is the threshold. So, therefore it is predicted as 0. So, let's take 1’s, so it is greater than 0.5, therefore it is predicted as 1. you go down a bit more. Sure. If you have seen row number 16. It is a 1, but we have predicted it as a 0. So, now let them let the learners pause and think, when the actual is 1 and we got it predicted as 0. Is it a false positive or a false negative? That is a question, just look at it go back and revisit, try to answer. Now, let's look at that number, why it has predicted it as 0, because we have given a test 0.34 threshold lesser than 0.5. So, it is a 0. Now, as sir said, if you play around with the threshold, for all problem, we might be able to increase our recall and precision accordingly if required. In fact, if you go back to the classification report. Yes. If you can just scroll up. Our precision for our problem is 0.61 and 0.39. Whereas the model, by the default setting of 0.5 is very good for 0.84 and 0.93. So, may be the users can go around and try to see how to change this threshold by, so that we increase the precision for 1, increase the recall for 1. But you should also keep in mind if you do some changes there, our accuracy will also change. Yes. So that will be done at the cost of accuracy. Cost of accuracy. Just for the interest of readers. We are not going to cover it in our videos, but you can play around and see what happens. So that's it. Anything else to add Malolan? I believe that should be fine. We will give you this code and the data set. So, do run it step by step to see if what you are getting and what we code is matching. Also do a check with how sir has interpreted it. Is your interpretation and our interpretation correct. Because there is a saying that the more you do the more you learn. So, please do it and any questions we will be happy to answer on discussION sessions and or live sessions. So, thank you Swami Thank you Malolan. Thank you have a nice day.