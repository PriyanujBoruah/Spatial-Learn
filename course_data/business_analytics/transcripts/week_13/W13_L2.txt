foreign [Music] goodness of a test and we are going to be demonstrating this technique in a tool which is going to be python so when you are going to perform a Chi Squared goodness of fit test we first need to know what are the steps that you are going to follow so in general we are going to have these steps so in step one we are going to get descriptive statistics and using these descriptive statistics we are going to narrow down on some possible candidates for the population distribution in Step 2 we are going to use visual tools to further check whether whatever we have identified in the descriptive statistics match with those that we have got through visuals so both these steps primarily focus on narrowing down on possible gases for the parent distribution so that is going to be step one and step two that we would be performing next in step three we would actually start creating the frequency table that is required then later on in Step 4 we would make appropriate conclusions right so here we will basically be creating the frequency table or computing the test statistic and so on and then we will be using it in Step 4 to make a conclusion of whether we are going to accept or reject the null hypothesis so this is going to be the first step procedure that you would be seeing uh in the tutorial that we are going to do having said that before I start on the pipe python tool please note our goal here is to not expose you to coding though we would be asking you to do a few bits of these codes on your own in future videos but our goal is to show you these steps to demonstrate these steps on the tool with that being said the code would be given to you it would be available for you to use we would now focus on implementing those steps that we just saw ok so in the first step in any tool that we are going to use we need to load the necessary packages the basic packages and then the data setting so let me just load the data set into this tool okay so for this demonstration I am going to use this data known as the data underscore uniform and has the name implies we are going to be demonstrating this tutorial for a disparent distribution that is let's say following a uniform distribution and appropriately we have got a data from that parent distribution which is the sample and that is data underscore uniform so I have got uploaded the data into my collab environment and I am importing the basic two basic packages which is numpy and pandas and then I am loading my data set into my environment which is going to be red in this in this variable known as DF and this DF has 51 observations and one column so this let us say is going to be the length of a scratch in millimeters on a car that is manufactured millimeters microns however you want to use it whatever unit but they are going to be length of scratches so we have 54 mm we have 52 mm 51 mm 53 mm so on and so forth like this we have 51 observations and that comes under this head known as the OBS the First Column is your index column so 0 to 50 would be your index and for each of these index the length of scratch is being given okay the first visualization that we are going to do is to plot a histogram for this particular data set so let's plot that and these are the commands for you so if I plot this what do I see I see that there is not one single Peak yeah I do have a peak here and here so that there are several Peaks so it is looking non-gaussian to me but some people might call this as a normal distribution as well let's say they could say that these two are just anomalies and it is going up and coming down but however these values are always four or more right so majority of them the values that are less than four are very very minimal most of them are four and we go up to 10 the frequency right so we could have either a normal or a poisson so those are the two possible content poison sorry not a poisson since its continuous it could be a uniform right so these are two possible basic contenders for us so let's keep that in mind from the uh visualized data so from this plot we see that it could either be a normal or it could be a uniform to narrow down further let's do some descriptive statistics so what do I get I have count which is 51 I have a mean of around 55 so that is the mean the standard deviation is extremely low so we have around 2.6 the minimum value is 50 the maximum value is 59 and on the different quantities 25 50 and 75 so 50 confile is basically going to be the median some people might be in interested in the variance this q and the cartosis that also you can get so the variance is going to be required of your standard deviation right so now having looked at this we can say ok given all of these values I will leave the interpretation of this q and kotosis to you but given all of these interpretations we can say all right this is not going to be a gaussian distribution so the alternative is going to be a uniform so we would proceed from this step we have narrowed down from let's say a poisson uniform binomial normal so on and so forth to a possible conductor contenders has normal or uniform and from that we are taking this as let's say an uniform and proceeding further now based on visualizations and some descriptive statistics we are telling it's uniform we need to perform it with a test and conclude that it is uniform so for performing the test we are going to include we are going to import all of these statistical packages for us once we have got the statistical packages we can further check or whether our guess of uniform is good or not using something known as the QQ plot the quantile quantile plot so the quantile quantile plot is going to check whether the proposed distribution and the theorized distribution or whether the observed distribution and the theorized distribution are matching in their tail portions right so if I put if I plot a QQ plot and if all of these values fall on this 45 degree 9 then my theorized distribution and the actual distribution or matching perfectly if not if there is very high deviation then I would say that my proposal and the theorized are not matching at all in my case most of the points are falling on this line and very very few points most of them are falling and very very few points are deviating from this 45 degree line and hence I can be certain with certain amount of confidence say yes my uniform distribution my assumption of uniform distribution fits well for the population given the QQ plot however the QQ plot only checks whether the distribution is fitting well on the tail regions if I have to do the same thing for checking them on the center regions I go for something known as the probability probability plot which is the pp plot so if the pp plot all the points fall on this 45 degree line then the center of the distribution that I am proposing and the center of the distribution of the theorized population also matches and in this case what I see is most of the points also fall on the line and very interestingly the deviations that happen in the QQ plot and the deviations that happen in the PPU plot are exactly in the same area right so they are following the 0.6 to 0.6.6 to 0.6 in both the pp and the QQ plot and this type of deviations will happen only if the population is a flat line which is going to be a uniform so my assumption of uniform for the population is actually a good fit can be concluded from this just as an exercise do one thing in this QQ plot instead of stats dot uniform use a different distribution start.poison or something else and you will see how erratic this line or these points are around the 45 degree line so that I would leave it as a self work for all of you to do now after doing all of this the histogram the descriptive statistics the pp and the QQ plot I can tell with certain amount of certainty that this distribution is indeed coming from a population which is uniform but these are all descriptives and visualizations I need to perform the chi-square goodness of the test get a test statistic and tell with statistical significance whether whatever I have told using visualizations is true or not for that we would start performing the Chi Squared goodness of fit test and just a recap in my previous video I didn't tell you what is the null and the hypothesis so here we see that the null hypothesis for the chi-squared goodness of the test is that the given this data follows a uniform distribution that is the population follows a uniform distribution is the null hypothesis and the alternative is that the given data does not follow a uniform distribution which means what the original path current distribution is non-uniform in nature so that is going to be the alternative so this is the null and the alternative for us and the first step in performing the chi-squared goodness of the test is to create the frequency table and the first step in that is to identify the bins so what I am going to do is I am going to cut this entire distribution into bins of equal length so what I am doing is based on the minimum and maximum value I am using this command called PD dot cut which is going to cut this entire data frame into bins and going to assign each of these observations for a particular bin so my first bin is going to be of my first observation is going to fall in a bin which is going to be of length 54.082 255.018 and each bin is going to be approximately of the same length so you calculate the length it should be coming to around 1.3 right so 1.3 to 1.4 so each of these observation now falls into a particular bin and in Step 2 I am creating a new data frame called df2 and for each bin that I have created I am going to find how many observations falls into that bin so that is going to be df2 is basically going to be representing my frequency table so in bin 1 which is going to be 50.33 to 51.26 there are going to be four observations in my data set right ah so if I just open this uniform data set right so um so if I add a filter and I want to do a number filter I will now type the bins into this since it's an open interval it's going to be greater than and is less than or equal to I see four observations in the sample and that is why my for each of these bins the number of observations is going to be varying so 4 6 5 5 so if I similarly as an exercise do it for the data set that is given to you check for this bin whether you are getting five observations for this bin whether you are getting 10 observations right so this is going to be the observed frequency Now using this I must now compute the expected frequency and for a uniform distribution there is something very beautiful that will happen so what is a uniform distribution it's going to be the the histogram for a uniform distribution if it's exactly right should look like this correct every value has equal number of observations so this is frequency and let's say this is the range right so if I plot a histogram uh for a uniform distribution a perfect uniform distribution then every value or every bucket should have the same number of observations right so if I have to do this then the probability in each of these is going to be the same let us say this is going to be x one this is going to be X2 this is going to be X3 the number of count over here is going to be X right so X1 is going to be equal to x x 2 is going to be equal to x x 3 is going to be equal to X so on and so forth let's say this is the kth bucket x k is going to be equal to X which means the probability in each of these is going to be X by n since x 1 plus x 2 plus 1 up to x k is going to be the number of observations that you have the probability space under each of these bins is going to be the same X by n which means what the value for all of these is going to be the mean value of your sample so if I take 4 6 5 10 and if I take the mean of these values that is going to be the expected frequency in any given bin because the distribution is uniform correct so that is going to be the expected frequency in each of these bins so now I have created my uh created my probability table of my frequency table for here I've got different bins and for each of these bins I've got an observed frequency and expected frequency now all I have to do is perform the chi Square the goodness of a test so I will use this command known as Chi Square and I would feed the observed frequency and expected frequency into this and I would run it so once I have run it I would get two values the first value is the computed Chi Square test statistic which is going to be 6.45 which is nothing but observed minus expected the whole squared by expected for each bin summed up for all of the bins that is going to be this value has a self work computed for this particular frequency table and see whether it is matching right so this is going to be that value and the second value that I get is the p-value correct so now that I've got these two I can use any one of the two methods to make a conclusion let's say I am going to use the first technique which is going to be based on the p-value right so if I have to conclude based on the p-value what I have to do I have to compare this value of 0.694 with our level of significance Alpha and if this 0.694 is less than the alpha I would say reject the null hypothesis which means I would say that the population does not follow a normal right so in our case let us take an alpha of 5 percent which is 0.05 and since this value of 0.694 is greater than in fact very very greater than 0.05 I would conclude do not reject the null hypothesis which means I would say that the population is indeed following a uniform distribution because I have got a sample that is law that is telling me not to reject the null hypothesis right so that would be the conclusion and when you use a p-value you can do something one step further you can actually go to a level and say that up to a level of significance of 0.7 because only at 0.7 this P value will become less than the alpha right so up to a level of 70 percent or 0.7 significance level I would not reject this I would not reject my null hypothesis for this particular data set tomorrow if a data set changes again I will have to do a P value test and conclude and then arrive at a significance level but given this sample up to a level of significance of 70 percent of 0.7 I would not reject the null at all and up to that level I would say that the population is indeed following a uniform distribution so that is the I added advantage that you get when you do a p p value test of course I could do um comparison with a computer with a tabulated test statistic and for that what I do is I use this command got called chi2.tpf and input the 95 percent confidence interval so 1 minus Alpha value so that is going to be 0.95 and for 0.95 n minus K minus 1 which is the degree of Freedom which is K minus P minus 1 which is going to be the number of bins 1 2 3 4 5 6 7 8 9 10. since I am going to split this into 10 bins so 10 minus 2 since for a uniform distribution I need two parameters the lower value and upper value so 10 minus 2 minus 1 so that is going to be 7 at a level of significance of 95 percent or a conference interval of 95 percent and uh bandwidth 7 degrees of freedom the tabulated value is going to be 14 and since this tabulated value is greater than my 6.4 the tabulated value is greater than my 6.4 I would not reject the null hypothesis and hence I can conclude that the original Parent distribution is indeed coming from a normal so indeed coming from a uniform since I am doing it for a uniform so this is how you perform the chi-square goodness of the test in Python so this tutorial we will stop it here and in the next tutorial we will see the same technique with a few catches that would be happening in um for a different data set