There is the data. I have taken an example of a typical business school admissions. Once again, let me tell you that this is an example created for the purpose of this class only. This data actually is not true data. Therefore, this in no way represents academic performance of 15 randomly selected students. So, any similarity is only coincidental. Let me put that disclaimer right away. So, right now, let us say that I want to predict the CGPA of these students in their MBA program. Now, I am thinking that if they had done well on their entrance examination, they may be performing well in their MBA program, or if they had done well in their MBA interviews, I hope that they will perform well in their MBA program, valid assumptions to have. And it is also backed up by the coefficient of correlation. The data says that CGPA in the MBA program is correlated with the entrance examination score, with a coefficient of correlation of 0.74 positive. So, if the entrance examination score is positive, we expect better CGPA in college, positive 0.74. Similarly, if the interview scores for this candidate was good, we expect their CGPA to be good. Because the correlation coefficient is 0.76. So, because of these two numbers, I think that these two are good explanatory variables, and using these two explanatory variables, I hope to explain the variation in the CGPA of these candidates in their MBA program. So, I wish to use these two explanatory variables to explain the variation in Y, Y in this case, my response variable is their CGPA in the MBA program. Disclaimer, this is synthetic data. So, now, if I look at individual influence of these, if I look at the individual influence of entrance examination on the CGPA during MBA, let us go to this. So, what I have done is, we have only considered one explanatory variable. So, this becomes a simple linear regression. A simple linear regression where only one explanatory variable, one response variable. If I run the regression and you know how to run the regression in Excel now. So, this is what I get, I got R to be 0.74, this R was same as 0.74, that I had here 0.74, same R because the same variables used. If I square the R, I get 0.55, let us check that. So, if I square this term, I am going to get 0.557. So, this standard error, we have already discussed this, this is our sigma of epsilon, this is the estimate of sigma of epsilon. Ideally speaking, this is what I call as, this is my Se, what is the difference between Se and sigma of epsilon? Sigma epsilon is the parameter value. However, to know the parameter value I need to know the entire population, I do not know the entire population, I only have 15 values in my sample. So, from the 15 values in the sample, I am estimating sigma of epsilon. This sigma of epsilon can be estimated using a sample value, which is Se, and currently we are saying that that value is 0.785. So, R squared is 0.55, which is not bad. Adjusted R squared, let us not look at it right now. Let us look at it only when we look at the multiple regression. This is still simple linear regression, only explanatory variable is the entrance examination score. So, simple linear regression. So, let us focus on 0.55, which is not bad at all, and standard error of 0.785. So, let us check if this regression is significant. We know how to read the regression output, we will directly go to this value. Do you recall what this value is? Do you recall what is this? This is the p value. This is the p value of the hypothesis that regression is not significant, null hypothesis is that regression is not significant. And the p value of 0.001, means that we will have to reject this null hypothesis, concluding that entrance examination does explain variation in the CGPA during their MBA program. What is the coefficient value, the beta 1 value, beta 1 value, this is the estimate of beta 1. So, let us call it b1. So, b1 is supposed to estimate beta 1, beta 1 is the slope. What is this beta 1, this is simple linear regression. So, this beta 1 is the marginal slope. One unit change in the examination score is expected to change the CGPA in the entrance examination by 0.72 units, that's the interpretation. Once again, the p value we saw, we recall this p value is going to be same as this p value, because essentially we are checking the same thing. So, this is the simple linear regression telling us that entrance examination is a good explanatory variable to have for the y that we are looking at. Let us look at the impact of the other explanatory variable, the interview scores. By the way, if you note, I mean, a reader would have already noticed that all the scores are on a scale of 0 to 10. So, let us look at the impact of interview scores on the CGPA during MBA, let us do that using SLR 2. I have considered only one explanatory variable, which is X2 now, I have removed X1. So, this is also a simple linear regression, where I am trying to study the impact of X2 on Y. Simple linear regression, the interpretation is fairly straightforward. 0.763 is the R, which is the coefficient of correlation which is same as this 0.763. The standard error, which is Se, this is Se for this regression, and this is my p value. So, my null hypothesis that regression is not significant has to be rejected, because the p value is very very small. What is the coefficient, this is beta 2, actually this is b2, which is an estimate of beta 2, and once again this is also a marginal slope. This is marginal slope for the second explanatory variable which is interview. Hope things are clear now. So, once again this proves that even interview is a good explanatory variable to have to explain the variation in Y. Therefore, now, let us go to the multiple linear regression. Multiple Linear Regression. The method of running multiple linear regression in Excel actually does not change. Do you want me to run it? Let us run it, I will show the execution again, execution of multiple regression model again. So, how did we run the regression earlier, we went to data, we went to data analysis, we went to regression. What is our Y? Our Y is this column of data. What is our X now? Instead of selecting a single column, I will actually select both the columns together. Excel understands that I have two explanatory variable now. Are there labels? Yes of course, there are labels. I want Excel to print the output here. So, let us look at this. So, this is my multiple linear regression output. Now, let us understand, first value is 0.86 which is the multiple R, what is this? What is this 0.86 value? What does the R in multiple regression correspond to? Let us go back to the PPT. What did we say about the multiple linear regression? Where did it go? Yes here. So, R is the correlation between the observed value of y and the fitted value of y. So, this 0.86 represents the correlation coefficient, coefficient of correlation between y and y hat. What is y? y are these values which are observed. What is y hat? y hat is the predicted value of y's. I should have asked Excel output for that also, I can show it here. I actually have the predicted values of y. Predicted values of y are here. So, the actual observed value of y is here. The predicted value of y is here. That is that value. So, this is that R squared, this is that multiple R. R squared is the explanatory power of this MRM of this model. So, what are we able to conclude from this value 0.74. We are going to say that using these two explanatory variables, X1 and X2, is able to explain 74 percent variation in the CGPA during MBA program. 74 percent of the variation is explained. You can get the same value of 0.74, remember how did we get this 0.74 from the ANOVA table? What was the sum of squares for the model divided by the total sum of squares? I get the same value 0.74051. So, out of the total sum of squares of 18.13, 13.43 are coming because of the regression. So, I am able to explain. How did this sum of squares, how are the sum of squares explained? We are saying it is because of the regression model. So, I am able to explain 74 percent variation in the response variable. Adjusted R, adjusted R squared, as we said we are using k is equal to 2, because there are two explanatory variables, n is equal to 15. This is my n, my k is equal to 2, my two explanatory variables, and therefore, Excel is going to print what is called as adjusted R squared, which is a more realistic view of R squared. So, to be on the conservative side, I will say that my explanatory power of regression is not actually 74 percent, it is actually 69 percent, just being conservative. So, this standard error is once again S of e, standard deviation of the error terms, which is an actually, which is trying to predict sigma of epsilon, which is the standard deviation of the error term. I want the population parameter, I am only going to get the sample value from the 15 observations that I have. Now, just like we looked at the ANOVA table for the simple linear regression, let us make sense of this ANOVA table. Why is this 14? This is 14, because this is n minus 1, 15 minus 1 is 14, I have this written down here. Why is this 2, because actually what is the regression equation? Regression equation is beta not plus beta 1 X1 plus beta 2 X2. There are three parameters that you are estimating. So, 3 minus 1 is 2, the other way to look at it is, there are two explanatory variables. So, this is 2. Now, 14 minus 2 is 12, which turns out to be n minus k minus 1. What is n? n is 15 what is k? k is 2, minus 1. so, 15 minus 3, 15 minus 3 is 12. So, how did we get this mean sum of squares, mean sum of squares is sum of squares divided by the degrees of freedom. So, this 6.71 is calculated as 13.43 divided by 2, this 0.39 is calculated as 4.7 divided by 12. And what is the F statistic? F statistic is the mean sum of squares for the regression, divided by the mean sum of squares for the residuals. So, this 17.12 is 6.71 divided by 0.39. Let us focus on this p value and get the insight, what is this p value correspond to? p value still corresponds to the same null hypothesis which was there in the simple linear regression. Simple linear regression null hypothesis, the main null hypothesis was saying anyway, that the regression is not significant, we can continue with the same, regression is not significant, and such a small p value tells us that not that null hypothesis has to be rejected and therefore, we conclude that the regression is significant. However, what are the estimates of the coefficients? These are the estimates of the coefficients. First of all let us make sure that they are all right, this beta 1, what is this null hypothesis? What is this p value correspond to? This p value corresponds to the null hypothesis that beta 1 is actually 0, against the alternate hypothesis that is beta 1 is not 0, p value of 0.01 means that this null hypothesis is rejected. Therefore, 0.455 is a good estimate of beta 1, we will call it b1, but it is an estimate of beta 1. Similarly, this p value corresponds to the null hypothesis that beta 2 is 0 against the alternate hypothesis that this beta 2 is not 0. p value less than 0.05 means that I reject this null hypothesis and conclude that beta 2 is definitely not 0. Look at the confidence interval, confidence interval is from 0.15 to 1.08, 0 is nowhere in there, which means that I am 95 percent confident that this beta 2 is not 0. So, this I call it b2, which is trying to estimate beta 2. So, what is my regression equation now? My regression equation, total regression equation including all the parameters is negative 0.7, which is the intercept negative 0.7 plus 0.455 X1 plus 0.622 X2. What is this 0.455? This is called the partial slope, as against the marginal slope in the simple linear regression. This was called the marginal slope. Now, in the multiple regression model, I am going to call this as partial slope. How do I interpret it again? Keeping X2 constant, one unit change in the entrance examination score is expected to increase a CGPA in college by 0.455 units. You have to keep saying that, keeping X2 constant. Since you have to keep saying that, this slope is called partial slope. How do you interpret this 0.622? You say that keeping the entrance examination scores constant, one unit increase in the interview score is expected to increase the CGPA in MBA program by 0.622 units. Therefore, it is called partial slope. I hope this is understandable. If this is understandable, we can actually end the session here and discuss the path diagram in the next session.